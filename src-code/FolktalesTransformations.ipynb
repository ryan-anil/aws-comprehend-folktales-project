{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fffec5",
   "metadata": {},
   "source": [
    "### First Steps\n",
    "\n",
    "Natural language processes require specific input files and formats in order to properly run their algorithms and produce meaningful outputs. Thus, it is always important to clean your input data, especially when it is text, before using any NLP methods. In this case, we wish to transform the text in folktales, which we have stored in various S3 buckets. AWS S3 stores all data in buckets and as bytes. This can cause textual data to be slightly modified with escape characters, which need to be removed before continuing further using Comprehend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e7fc3218",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "buckets = ['arabian-folktales', 'chinese-folktales', 'english-folktales','german-folktales', 'indian-folktales', 'russian-folktales']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef64d0e",
   "metadata": {},
   "source": [
    "The following loop cleans every folktales text file and creates new S3 buckets to store the new clean files. Because S3 stores every object in bytes, we must decode each text file so that the bytes are recomposed into a 'utf-8' string which we can manipulate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "395d41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for currBucket in buckets:\n",
    "    newBucket = currBucket + \"-transformed\"\n",
    "    s3.create_bucket(Bucket = newBucket)\n",
    "    for item in s3.list_objects_v2(Bucket = currBucket).get('Contents'):\n",
    "        name = item.get('Key')\n",
    "        obj = s3.get_object(Bucket = currBucket, Key = name)\n",
    "        text = obj.get('Body').read().decode('utf-8')\n",
    "        text = text.replace('\\n', \" \")\n",
    "        text = text.replace('\\r', \"\")\n",
    "        s3.put_object(Bucket = newBucket, Body = text, Key = name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
